<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>ARQUITECTURA DE COMPUTADORAS</title>
    <link href="https://fonts.googleapis.com/css2?family=DotGothic16&family=Special+Elite&family=Zen+Kaku+Gothic+Antique&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="estilos.css">
  </head>
  <body>
<a href="index.html" class="estilos">menu</a>
    <h1 class="TituloPrincipal">UNIDAD 04</h1>
    <hr>
    <h2 class="tema">4.1 ASPEECTOS BÁSICOS DE LA PROGRAMACION PARALELA</h2>

    <p class="texto">La computación paralela es una manera de cómputo en la que muchas indicaciones se ejecutan simultáneamente, operando sobre el inicio de que inconvenientes gigantes, comunmente tienen la posibilidad de dividir en unos más pequeños, que después son resueltos al mismo tiempo. tienen la posibilidad de clasificarse de acuerdo con el grado de paralelismo que admite su hardware: grupos con procesadores multinúcleo y multi-procesador que poseen diversos recursos de procesamiento en una sola máquina y los clústeres, MPPS y grids que usan diversos conjuntos para laborar en la misma labor. Frecuentemente, para apresurar labores concretas, se aplican arquitecturas especializadas de computación en paralelo al lado de procesadores clásicos.<br><br>
Utiliza al mismo tiempo diversos recursos de procesamiento para solucionar un problema. Esto se consigue por medio de la separación del problema en piezas independientes debido a lo cual cada componente de procesamiento logre llevar a cabo su parte del algoritmo de forma simultánea con los demás. Los recursos de procesamiento son diferentes e integran recursos como por ejemplo una PC con diversos procesadores, diversos pcs en red, hardware especializado, o cualquier conjunción de los anteriores</p><br>
    <h2 class="tema">4.2 TIPOS DE COMPUTACION PARALELA </h2>
    <h3 class="subtema">4.2.1 Clasificacion </h3>
    <h3 class="subtitulo">Nivel bit</h3>
    <p class="texto">La aceleración en la arquitectura de computadores se lograba en enorme medida duplicando la medida del vocablo en la PC, la proporción de información que el procesador puede manejar por periodo. El incremento del tamaño del vocablo disminuye el número de indicaciones que el procesador debería llevar a cabo para hacer una operación en cambiantes cuyos tamaños son más grandes que la longitud del vocablo. Ejemplificando, una vez que un procesador de 8 bits debería sumar 2 completos de 16 bits, el procesador primero debería aumentar los 8 bits de orden inferior de cada número completo con la instrucción de suma, luego, adicionar los 8 bits de orden preeminente usando la instrucción de aumento con acarreo que tiene presente el bit de acarreo de la suma de orden inferior, en esta situación un procesador de 8 bits necesita 2 normas para terminar una sola operación, en donde un procesador de 16 bits requiere una sola instrucción para lograr completarla.</p>
    <h3 class="subtitulo">Nivel de instruccion</h3>
    <p class="texto">Un programa de ordenador es, esencialmente, una serie de indicaciones ejecutadas por un procesador. Estas normas tienen la posibilidad de reordenarse y combinarse en conjuntos que después son ejecutadas en paralelo sin modificar el resultado del programa. Esto se sabe como paralelismo a grado de instrucción. Los procesadores modernos poseen 'pipeline' de normas de numerosas fases. Cada fase en el pipeline corresponde a una acción distinto que el procesador hace en la instrucción que corresponde a la fase; un procesador con un pipeline de N fases puede tener hasta n normas diferentes en diferentes fases de finalización. El ejemplo canónico de un procesador segmentado es un procesador RISC, con 5 fases: solicitar instrucción, decodificar, realizar, ingreso a la memoria y escritura. El procesador Pentium 4 poseía un pipeline de 35 fases.</p>
    <h3 class="subtitulo">Paralelismo de datos</h3>
    <p class="texto">El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se concentra en el reparto de los datos entre los diferentes nodos computacionales que tienen que tratarse en paralelo. Muchas de las aplicaciones científicas y de ingeniería presentan paralelismo de datos. Una dependencia de terminación de periodo es la dependencia de una relación de un periodo en la salida de una o más interrelaciones anteriores. Las dependencias de terminación de periodo evitan la paralización de ciclos.</p>
    <h3 class="subtitulo">Paralelismo de tareas</h3>
    <p class="texto">El paralelismo de labores es la característica de un programa paralelo en la que cálculos del todo diferentes tienen la posibilidad de hacer en cualquier grupo igual o distinto de datos, Esto contrasta con el paralelismo de datos, donde se hace el mismo cálculo en diversos o mismos equipos de datos. El paralelismo de labores en la mayoría de los casos no escala con la medida de un problema.
<h3 class="subtema">4.2.2 Arquitectura de computadoras secuenciales </h3>
<h3 class="subtitulo">SISD (Single Instruction stream, Single Data stream) </h3>
<p class="texto">Flujo exclusivo de normas y flujo exclusivo de datos. Este el término de arquitectura serie de Von Neumann donde, en cualquier instante, solamente se está ejecutando una exclusiva instrucción. Constantemente a los SISD se les conoce como computadores serie escalares. Cada una de las maquinas SISD tienen un registro sencilla que se denomina contador de programa que garantiza la ejecución en serie del programa.</p>
<h3 class="subtitulo">MISD (Multiple Instruction stream, Single Data stream)</h3>
<p class="texto">Flujo múltiple de normas y exclusivo flujo de datos. Esto quiere decir que numerosas indicaciones trabajan sobre el mismo y exclusivo pedazo de datos. Esta clase de aparatos tienen la posibilidad de interpretar de 2 modalidades. Una es tener en cuenta la clase de aparatos que requerirían que unidades de procesamiento diferentes recibieran indicaciones diversas operando sobre los mismos datos. </p>
<h3 class="subtitulo">SIMD (Single Instruction stream, Multiple Data stream)</h3>
<p class="texto"> Flujo de instrucción sencilla y flujo de datos múltiple. Esto quiere decir que una exclusiva instrucción es aplicada sobre diferentes datos simultáneamente. En las máquinas de esta clase, algunas unidades de procesado diferentes son invocadas por una exclusiva unidad de control. Al igual que las MISD, las SIMD aguantan procesamiento vectorial (matricial) asignando cada componente del vector a una unidad servible distinto para procesamiento concurrente.</p>
<h3 class="subtema">4.2.3 Organizacion de direcciones de memoria </h3>
<p class="texto">La memoria de ingreso secuencial son memorias en la cuales para entrar a un registro en especial se deben leer registro por registro a partir de el principio hasta conseguir el registro especial que tiene el dato que es preciso. Estas memorias se catalogan en:</p>
<ul class="lista">
<li>Registros de movimiento</li>
<li>Dispositivos por acoplamiento por carga</li>
<li>Memorias de burbuja</li>
</ul>
    <h2 class="tema">4.3 SISTEMAS DE MEMORIA COMPARTIDA</h2>
    <p class="texto">La memoria compartida es ese tipo de memoria que podría ser accedida por diversas programas, así sea para comunicarse entre ellos o para eludir copias redundantes. La memoria compartida es un modo eficaz de pasar datos entre aplicaciones. Dependiendo del entorno, los programas tienen la posibilidad de ejecutarse en un mismo procesador o en procesadores separados. La memoria utilizada entre 2 hilos de ejecución en un mismo programa se sabe además como memoria compartida.</p>
<h3 class="subtema">4.3.1 Redes de medio compartido </h3>
<p class="texto">Los sistemas multiprocesadores son arquitecturas MIMD con memoria compartida. Poseen un exclusivo espacio de direcciones para todos los procesadores y los mecanismos de comunicación se fundamentan en el paso de mensajes a partir de la perspectiva del programador. Ya que los multiprocesadores comparten diferentes módulos de memoria, logrando entrar a un mismo módulo diversos procesadores, a los multiprocesadores además se les llama sistemas de memoria compartida.</p>
<h3 class="subtema">4.3.2 Redes conmutadas</h3>
<p class="texto">Dependiendo de la manera en que los procesadores comparten la memoria, se ordenan en sistemas multiprocesador UMA, NUMA y COMA. Multiproceso es comúnmente conocido como la utilización de diversos procesos concurrentes en un sistema en vez de un exclusivo proceso en un momento definido. Como la multitarea que posibilita a diversos procesos compartir una exclusiva CPU, diversas CPUs tienen la posibilidad de ser usados para llevar a cabo diversos hilos en un exclusivo proceso. El multiproceso para labores en general es, constantemente, bastante difícil de lograr ya que puede haber diversos programas manejando datos internos (conocido como estado o contexto) a la vez.</p>
    <h2 class="tema">4.4 SISTEMAS DE MEMORIA DISTRIBUIDA </h2>
    <h3 class="subtema">4.4.1 Redes de interconexión estáticas </h3>
    <p class="texto">Una red estática es una red cuya topología queda determinada de forma definitiva y estable a lo largo de la obra de la máquina paralela. La red sencillamente une los múltiples recursos según una configuración dada. Se usa más que nada en la situación de los multicomputadores para conectar los múltiples procesadores que tiene la máquina. Por la red únicamente transitan los mensajes entre procesadores, por lo cual se plantea que la red muestra un acoplamiento débil. Generalmente, en las redes fijas se pide escasa carga a la red. Una red dinámica es una red cuya topología puede variar a lo largo de el curso de la ejecución de un programa paralelo o entre 2 ejecuciones de programa <br><br>
      La red está conformada por recursos materiales específicos, denominados commutadores o switches. Las redes dinámicas se usan más que nada en los multiprocesadores. En esta situación, la red une los procesadores a los bancos de memoria central. Cualquier ingreso de un procesador a la memoria (bien sea para entrar a los datos o a las instrucciones) debería pasar por medio de la red, por lo se plantea que la red tiene un acoplamiento profundo. La red debería tener un rendimiento drásticamente bueno para no demorar bastante a los procesadores que entran a memoria.<br>

      Los sistemas de memoria distribuida o multicomputadores tienen la posibilidad de ser de 2 tipos básicos. El primer de ellos consta de un exclusivo computador con diversas CPUs comunicadas por un bus de datos en lo que en el segundo se usan diversas computadores, cada uno con su propio procesador, enlazados por una red de interconexión más o menos inmediata. Sobre los sistemas de multicomputadores de memoria distribuida, se simula memorias compartidas. Se utilizan los mecanismos de comunicación y sincronización de sistemas multiprocesadores.<br><br>
      Las redes estáticas emplean enlaces directos fijos entre los nodos. Estos enlaces, una vez fabricado el sistema son difíciles de cambiar, por lo que la escalabilidad de estas topologías es baja. Las redes estáticas pueden utilizarse con eficiencia en los sistemas en que pueden predecirse el tipo de tráfico de comunicaciones entre sus procesadores.
    </p>
    <h2 class="tema">4.5 CASOS DE ESTUDIO</h2>
    <p class="texto">
Por varios motivos, el procesamiento compartido se convirtió en un área de enorme trascendencia e interés en la Ciencia de la Computación, produciendo profundas transformaciones en las líneas de I/D. Atrae hacer indagación en la descripción, transformación, mejora y evaluación de algoritmos distribuidos y paralelos. Esto incluye el diseño y desarrollo de sistemas paralelos, la transformación de algoritmos secuenciales en paralelos, y las métricas de evaluación de performance sobre diversas plataformas de soporte (hardware y software). Más allá de las mejoras constantes en las arquitecturas físicas de soporte, uno de los más grandes retos se reúne en cómo aprovechar al mayor la potencia de las mismas. Atrae hacer indagación en la explicación, transformación, mejora y evaluación de algoritmos distribuidos y paralelos. Esto incluye el diseño y desarrollo de sistemas paralelos, la transformación de algoritmos secuenciales en paralelos, y las métricas de evaluación de performance sobre diversas plataformas de soporte (hardware y software). Más allá de las mejoras constantes en las arquitecturas físicas de soporte, uno de los más grandes retos se concentra en cómo aprovechar al más alto la potencia de las mismas.</p>
  </body>
<a href="index.html" class="estilos">menu</a>
</html>
